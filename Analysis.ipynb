{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Polarizing Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import dill\n",
    "import pandas as pd\n",
    "from heapq import nlargest, nsmallest\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_polarizing_words(model, countVectorizer, n):\n",
    "    print('coefficient shape', model.coef_.shape)\n",
    "    print('coefficients', model.coef_[:10])\n",
    "    if model.coef_.shape[0] == 1:\n",
    "        coefficients = [(i,c) for i,c in enumerate(model.coef_[0])]\n",
    "    else:\n",
    "        coefficients = [(i,c) for i,c in enumerate(model.coef_[1])]\n",
    "\n",
    "    id2word = countVectorizer.get_feature_names()\n",
    "    strongest_positive = [(id2word[i],coef) for i,coef in nlargest(n, coefficients[::], key=lambda x: x[1])]\n",
    "    strongest_negative = [(id2word[i],coef) for i,coef in nsmallest(n, coefficients, key=lambda x: x[1])]\n",
    "    print('\\n Most positive words were:') \n",
    "    for (word,coef) in strongest_positive:\n",
    "        print('{}: {}'.format(word, coef))\n",
    "    print('\\n Most negative words were:') \n",
    "    for (word,coef) in strongest_negative:\n",
    "        print('{}: {}'.format(word, coef))\n",
    "    return strongest_positive, strongest_negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "                lowercase=True, max_df=1.0, max_features=10000, min_df=1,\n",
      "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
      "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, vocabulary=None)\n",
      "TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)\n"
     ]
    }
   ],
   "source": [
    "with open('model.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    "countVectorizer = dill.load(open('countVectorizer.pk', 'rb'))\n",
    "tfidfVectorizer = dill.load(open('tfidfVectorizer.pk', 'rb'))\n",
    "print(countVectorizer)\n",
    "print(tfidfVectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('india', 1.9642870153858585)\n",
      "('minister', 1.7708642431855597)\n",
      "('modi', 1.759084143798483)\n",
      "('delhi', 1.7335591048198171)\n",
      "('indiafightscorona', 1.6938274054719575)\n",
      "('coronavirusoutbreak', 1.693810089801157)\n",
      "('pakistan', 1.6929342138951264)\n",
      "('total', 1.6897931509367916)\n",
      "('indian', 1.6756860007004355)\n",
      "('against', 1.675116671743758)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('bitch', 0.5973764007285363),\n",
       " ('ima', 0.59876360863479),\n",
       " ('allergies', 0.6215909044448146),\n",
       " ('nigga', 0.6255835136610358),\n",
       " ('shit', 0.6282215703470247),\n",
       " ('niggas', 0.6379830826025679),\n",
       " ('fuck', 0.6387401141039828),\n",
       " ('birthday', 0.6417182930979828),\n",
       " ('im', 0.6479595750546829),\n",
       " ('aint', 0.6488858242604939)]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "\n",
    "n = 10\n",
    "threshold = 0\n",
    "counts = np.sum(model.feature_count_,axis=0)\n",
    "id2word = np.array(countVectorizer.get_feature_names())[counts > threshold]\n",
    "coefficients = (model.feature_log_prob_[0] / model.feature_log_prob_[1])[counts > threshold]\n",
    "sorted_coef = (sorted([(id2word[i],c) for i,c in enumerate(coefficients)], key=lambda x:x[1]))\n",
    "\n",
    "for word in sorted_coef[-n:][::-1]:\n",
    "    print(word)\n",
    "sorted_coef[:n]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis using model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# store vectorizers and model\n",
    "dill.dump(countVectorizer, open('countVectorizer.pk', 'wb'))\n",
    "dill.dump(tfidfVectorizer, open('tfidfVectorizer.pk', 'wb'))\n",
    "with open('model.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "\n",
    "# load vectorizers and model\n",
    "with open('model.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    "countVectorizer = dill.load(open('countVectorizer.pk', 'rb'))\n",
    "tfidfVectorizer = dill.load(open('tfidfVectorizer.pk', 'rb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
